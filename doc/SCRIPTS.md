# CastANet Python scripts

CastANet scripts allow batch processing of plant root scans.
Use `castanet train` to fine-tune a model to identify mycorrhizal structures
in manually annotated pictures generated by any device. 
Pre-trained models for ink-stained root
images acquired with a flatbed scanner are available.
You can also use files obtained from a confocal laser-scanning microscope or
an epifluorescence microscope.
Use `castanet predict` for high-throughput labelling of mycorrhizal
structures in JPEG or TIFF images.

## CastANet usage


```
usage: castanet.py [-h] {train,predict} ...

CastANet command-line arguments.

positional arguments:
  {train,predict}  action to be performed.
    train          learns how to identify AMF structures.
    predict        predicts AMF structures.

optional arguments:
  -h, --help       show this help message and exit
```

### Training mode

Here is the initial, learning step, where you allow the model to determine how
to identify mycorrhizal structures using a manually annotated set of root
images. You can either train a model from scratch or fine-tune a pre-trained
model. Although low-resolution pictures allow running this script on a personal
computer, using high-performance computing (HPC) is recommended.

```
usage: castanet.py train [-h] [-t EDGE] [-b NUM] [-d N%] [-e NUM] [-f N%]
                         [-o DIR] [-l ID | -m H5] [-v N%]
                         [image [image ...]]

positional arguments:
  image                 plant root scan to be processed.
                        default value: *jpg

optional arguments:
  -h, --help            show this help message and exit
  -t EDGE, --tile EDGE  tile edge (in pixels) used for image segmentation.
                        default value: 40 pixels
  -b NUM, --batch NUM   training batch size.
                        default value: 32
  -d N%, --drop N%      percentage of background tiles to be skipped.
                        default value: 50%
  -e NUM, --epochs NUM  number of epochs to run.
                        default value: 100
  -f N%, --fraction N%  Percentage of tiles used for validation.
                        default value: 15%
  -o DIR, --output DIR  output directory for training files.
                        defaults to current directory.
  -l ID, --level ID     Annotation level identifier.
                        choices: {colonization, arb_vesicles, all_features}
                        default value: colonization
  -m H5, --model H5     path to the pre-trained model.
                        default value: none
  -v N%, --validate N%  percentage of tiles to be used for validation.
                        default value: 30%
```


### Prediction mode

Run CastANet prediction mode to perform automatic annotations of root images. 
Prediction relies on a pre-trained model that can be obtained here **(link)**
or generated from a custom set of training images using the training mode (see above). 

```
usage: castanet.py predict [-h] [-t EDGE] [-a] [-c N] H5 [image [image ...]]

positional arguments:
  H5                    path to the pre-trained model.
  image                 plant root scan to be processed.
                        defaults to JPEG files in the current directory.

optional arguments:
  -h, --help            show this help message and exit
  -t EDGE, --tile EDGE  tile edge (in pixels) used for image segmentation.
                        default value: 40 pixels
  -a, --activation_map  Generate class activation map (takes some time).
                        default value: False
  -c N, --colormap N    OpenCV colormap (see OpenCV documentation).
                        default value: 2 (cv2.COLORMAP_JET)
```
