# CastANet Python scripts

CastANet scripts allow batch processing of plant root scans.
Use `castanet train` to fine-tune a model to identify mycorrhizal structures
in manually annotated pictures generated by any device. 
Pre-trained models for ink-stained root
images acquired with a flatbed scanner are available.
You can also use files obtained from a confocal laser-scanning microscope or
an epifluorescence microscope.
Use `castanet predict` for high-throughput labelling of mycorrhizal
structures in JPEG or TIFF images.

## CastANet usage


```
usage: castanet.py [-h] [-t EDGE] {train,predict} ...

CastANet command-line arguments.

positional arguments:
  {train,predict}       action to be performed.
    train               learns how to identify AMF structures.
    predict             predicts AMF structures.

optional arguments:
  -h, --help            show this help message and exit
  -t EDGE, --tile EDGE  tile edge (in pixels) used for image segmentation.
                        default value: 40 pixels
```

### Training mode

Here is the initial, learning step, where you allow the model to determine how
to identify mycorrhizal structures using a manually annotated set of root
images. You can either train a model from scratch or fine-tune a pre-trained
model. Although low-resolution pictures allow running this script on a personal
computer, using high-performance computing (HPC) is recommended.

```
usage: castanet.py train [-h] [-b NUM] [-d N%] [-e NUM] [-l ID | -m H5]
                         [-v N%]
                         [image [image ...]]

positional arguments:
  image                 plant root scan to be processed.
                        default value: *jpg

optional arguments:
  -h, --help            show this help message and exit
  -b NUM, --batch NUM   training batch size.
                        default value: 32
  -d N%, --drop N%      percentage of background tiles to be skipped.
                        default value: 50%
  -e NUM, --epochs NUM  number of epochs to run.
                        default value: 100
  -l ID, --level ID     Annotation level identifier.
                        choices: {colonization, arb_vesicles, all_features}
                        default value: colonization
  -m H5, --model H5     path to the pre-trained model.
                        default value: none
  -v N%, --validate N%  percentage of tiles to be used for validation.
                        default value: 30%
```


### Prediction mode

Run the Python script in prediction mode when you want to annotate root images
automatically. Prediction relies on a pre-trained model (see training mode
above). The results obtained through computer prediction are probabilities.
Users should double-check results using the CastANet browser before calculating
colonization levels..

```
usage: castanet.py predict [-h] H5 [image [image ...]]

positional arguments:
  H5          path to the pre-trained model.
  image       plant root scan to be processed.
              default value: *jpg

optional arguments:
  -h, --help  show this help message and exit
```
